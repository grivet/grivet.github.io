<!doctype html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="data:,"/>
    <title>U256 | A fast lockless MPSC queue</title>
    <link rel="stylesheet" href="../style.css"/>

    
</head>
<body>
    <header>
        <div>
            <a href="../">Home</a>
            <a rel="me" href="https://hachyderm.io/@grive">Mastodon</a>
        </div>
<div id='navbar'>
<span><a href="../notes">notes</a></span>
<span><a href="./">posts</a></span>
</div>
    </header>

<main>
    <div class="title">
        <h1>A fast lockless MPSC queue</h1>
        <time datetime="2021-02-21">2021-02-21</time>
    </div>
<blockquote>
<p>Code available on <a href="https://github.com/grivet/mpsc-queue">github</a>.</p>
</blockquote>
<p>Sharing mutable data kills concurrency, but using multicore systems
efficiently often requires dividing work between active threads.</p>
<p>By carefully planning data accesses, it is possible to reduce their
synchronization overhead. If mutable data is isolated, there is no need
to take a lock before modifying it as we are assured to be the only one
currently accessing it.</p>
<p>To isolate data, different approaches are possible. <a href="https://harelang.org/">Some</a> languages choose
to only allow a single execution thread and rely on process isolation provided
by the operating system. <a href="https://www.rust-lang.org/">Others</a> will support telling the compiler when data has <em>moved</em>
between accessors to enforce either unique access or explicit synchronization.</p>
<p>As usual with C, we are left to fend for ourselves. One classical solution to this
problem is message passing, which can be used to crudely express the <em>move</em> semantic
of passing a bit of isolated data from one thread to the next.
Unfortunately enforcing unique access is then usually done by humans
with the help of a few comments.</p>
<p>To implement message passing, a message queue is used and becomes a critical primitive.</p>
<p>I found the <a href="http://www.1024cores.net/home/lock-free-algorithms/queues/intrusive-mpsc-node-based-queue">queue described by Dmitri Vyukov</a> simple and practical if cooperative
threads are used. It is an MPSC queue, which limits the need for synchronization.
This in turn allows keeping it light and performant.</p>
<p>It offers interesting properties but its apparent simplicity trades for subtle caveats,
that I thought should be explored a bit.</p>
<h2>Properties</h2>
<h3>Lockless MPSC</h3>
<p>This is a lockless multi-producer, single-consumer (MPSC) queue. Message passing is done
many-to-one, with any number of sender to a single recipient. Note that lockless does not mean
lock-free. While no lock is ever used within the queue operation, there is a potential for livelocking
threads if used improperly.</p>
<h3>Intrusive &amp; unbounded</h3>
<p>This message queue is an intrusive linked-list, meaning that a queue node is part of the element
being inserted in the list. Consequently, a part of that element is necessarily modified by any
queue operation.</p>
<p>Another result from its intrusiveness is that the queue itself does not bound the number of enqueued elements.
Instead, backpressure is handled when generating the inserted elements (during allocation typically).</p>
<h3>Per-producer FIFO</h3>
<p>Queue ordering is per-producer FIFO, i.e. it keeps the order of insertions from each producer point of view.
However, between producers no ordering is guaranteed, unless additional synchronization is used.</p>
<h3>Obstruction-free</h3>
<p>Thread synchronization is done at a single point using an atomic <strong>exchange</strong>.
It reduces the insertion overhead greatly compared to <strong>compare-exchange</strong> based queues as it
does not require a synchronization loop to enforce correctness of writes. It elegantly sidestep
the <em>ABA</em> problem such loop creates and obviates the need to handle it.</p>
<p>Without the <code>CMPXCHG</code> loop, insertion and peeking is done in a finite and constant number of steps.
Removal however requires producers to complete their writes (which is explained later), making the consumer
dependent on other threads forward-progress. As such the structure is obstruction-free only.</p>
<p>Another formulation of that property is that this structure relies on cooperative threads to avoid livelock.
Producer threads must not be cancelled while inserting nodes in the queue, as it might block a consumer from
progressing.</p>
<p>As an intrusive, lean linked-list based queue, this structure can be useful for low-latency systems,
such as <em>thread-per-core</em> applications. It could also be used to implement the
<a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a>.</p>
<h2>Operations</h2>
<h3>Insertion</h3>
<p>The queue is implemented using a singly-linked list. Insertion is done at the
back of the queue. First the current end is swapped with the new node atomically.
The previous end is then updated to point to the new node. To follow Vyukov's
nomenclature, the end-node of the chain is the head. A producer will
only manipulate the head.</p>
<pre><code>
Before: the queue is in a consistent state and its end currently points to a node 'C'.
Thread 1 is going to insert a node 'D'.

      ,-----.   ,-----.   ,-----.                   ,-----.
- - -&gt;|  A  +--&gt;|  B  +--&gt;|  C  +--&gt; //             |  D  +--&gt; //
      `-----'   `-----'   `-----'                   `1----'
                             ^
  head +---------------------'


Insertion part A: the head pointer is swapped by thread 1, pointing to 'D'.

      ,-----.   ,-----.   ,-----.       ,-----.
- - -&gt;|  A  +--&gt;|  B  +--&gt;|  C  +--&gt; // |  D  +--&gt; //
      `-----'   `-----'   `-----'       `1----'
                                           ^
  head +-----------------------------------'


Insertion part B: thread 1 links 'C' to 'D'.

      ,-----.   ,-----.   ,-----.   ,-----.
- - -&gt;|  A  +--&gt;|  B  +--&gt;|  C  +--&gt;|  D  +--&gt; //
      `-----'   `-----'   `1----'   `-----'
                                       ^
  head +-------------------------------'

</code></pre>
<p>The head swap is atomic, however the link from the previous head to the new
one is done in a separate operation. Any number of threads can execute the first
part of insertion concurrently. The head can be moved around several
times in any execution order, and it will remain correct in the sense that it
will still point to the last enqueued element.</p>
<p>Closing the chain however is done in a second, separate operation.
Until the chain is closed, it remains in an inconsistent state.
In that state, the previous seen head (C in this example) still points to <code>NULL</code>,
but the next published head is D.</p>
<pre><code>
Multiple threads inserting concurrently:

      ,-----.   ,-----.   ,-----.       ,-----.   ,-----.       ,-----.   ,-----.
- - -&gt;|  A  +--&gt;|  B  +--&gt;|  C  +--&gt; // |  D  +--&gt;|  E  +--&gt; // |  F  +--&gt;|  G  +--&gt; //
      `-----'   `-----'   `-----'       `1----'   `2----'       `3----'   `4----'
                                                                             ^
  head +---------------------------------------------------------------------'


The consumer can only read until 'C', waiting on thread 1 to finish the insertion.
Threads 2 and 4 have finished inserting. Threads 1 and 3 are between part A and B.

</code></pre>
<p>Considering a series of insertions, the queue state will remain consistent
and their order is compatible with their precedence, thus this operation
is serializable. However, because an insertion consists in two separate memory
transactions, it is not linearizable.</p>
<h3>Removal</h3>
<p>The consumer must deal with the queue inconsistency. It will manipulate
the tail of the queue and move it along the last consumed elements.</p>
<pre><code>
Consumer reads from the tail:

        ,------.   ,-----.   ,-----.   ,-----.
        | stub +--&gt;|  A  +--&gt;|  B  +--&gt;|  C  +--&gt; //
        `------'   `-----'   `-----'   `-----'
           ^                              ^
  tail +---'                              |
  head +----------------------------------'

The tail first points to stub. As it is a known sentinel,
it is skipped and 'A' is returned, then 'B', then 'C'.

</code></pre>
<p>When an end of the chain of elements is found (the next pointer is <code>NULL</code>),
the tail is compared with the head.</p>
<p>If they point to different addresses, then the queue is in an inconsistent
state: the tail cannot move forward as the next is <code>NULL</code>, but the head is not
the last element in the chain: this can only happen if the chain is broken.</p>
<pre><code>
Reading in inconsistent state:

        ,------.   ,-----.   ,-----.   ,-----.       ,-----.
        | stub +--&gt;|  A  +--&gt;|  B  +--&gt;|  C  +--&gt; // |  D  +--&gt; //
        `------'   `-----'   `-----'   `-----'       `-----'
                                          ^             ^
  tail +----------------------------------'             |
  head +------------------------------------------------'

As the tail cannot go past 'C', if the head and tail points to different nodes,
the queue is known to be inconsistent.

</code></pre>
<p>In this case, the consumer must wait for the producer to finish writing the
next pointer of its current tail.</p>
<p>Removal is in most cases (when there are elements in the queue)
accomplished without using atomics, until the last element of the queue.
There, the head is atomically loaded. If the queue is in a consistent state,
the head is moved back to the queue stub by inserting the latter in the queue:
ending the queue is the same as an insertion, which is one atomic exchange.</p>
<pre><code>
Emptying the queue in a consistent state:

The consumer read 'D' already and tries to get the next node.

        ,------.   ,-----.   ,-----.   ,-----.   ,-----.
        | stub +--&gt;|  A  +--&gt;|  B  +--&gt;|  C  +--&gt;|  D  +--&gt; //
        `------'   `-----'   `-----'   `-----'   `-----'
                                                    ^^
  tail +--------------------------------------------'|
  head +---------------------------------------------'

As head and tail are equal, insert the queue stub:

        ,------.       ,-----.   ,-----.   ,-----.   ,-----.   ,------.
        | stub +--&gt; // |  A  +--&gt;|  B  +--&gt;|  C  +--&gt;|  D  +--&gt;| stub +--&gt; //
        `------'       `-----'   `-----'   `-----'   `-----'   `------'
                                                        ^         ^
  tail +------------------------------------------------'         |
  head +----------------------------------------------------------'

        ,------.
        | stub +--&gt; //
        `------'
           ^^
  tail +---'|
  head +----'

Next 'read', skip the stub and return NULL: the queue is empty.

</code></pre>
<h2>Usage</h2>
<h3>Semantic</h3>
<p>The queue can be in transient inconsistent states. The reader needs to <code>peek</code>
into the queue and check for inconsistencies before removing an element. Getting
into a consistent state is dependent upon producers completing their two-part writes.</p>
<p>A full <code>pop</code> operation means looping <code>peek</code> on the queue until it is either known empty or an
element is returned. The original queue as described by Vyukov does not distinguish between
an empty queue and an inconsistent queue, in both cases <code>NULL</code> is returned. This is
insufficient to efficiently implement <code>pop</code>, as different behavior is expected depending
on the queue state.</p>
<p>If the queue is empty, we can stop polling altogether. If it is inconsistent, we can
expect it resolved shorty and we should retry for a time. If neither, an element should
be available and polling stopped.</p>
<p>Thus I named the core removal function <code>mpsc_queue_poll</code>, which returns three possible values:</p>
<ul>
<li><code>MPSC_QUEUE_EMPTY</code>, meaning that the queue has no elements.</li>
<li><code>MPSC_QUEUE_ITEM</code>, in which case the given pointer is set to the removed element.</li>
<li><code>MPSC_QUEUE_RETRY</code>, signaling that a producer has not yet finished writing and polling should
be attempted again soon.</li>
</ul>
<p>Properly determining the state of the queue requires an additional operation over the
ones described in Vyukov implementation: when the <code>tail</code> is on the <code>stub</code> and there is
no <code>next</code> available, then we need to read and check against the <code>head</code> to decide whether
the queue is empty or inconsistent.</p>
<p>This is a small overhead, that allows properly implementing the <code>pop</code> polling loop.</p>
<h3>Safety</h3>
<p>If a producer was suspended after exchanging the head, but before linking to the new one,
the consumer is blocked from reading until the producer resumes. If the producer is cancelled,
then the consumer will never be able to access the remaining entries.</p>
<p>If the producers are very rarely or never suspended, then inconsistent states should
be short and rare. Producers should never insert while being cancellable.</p>
<p>The <code>pop</code> loop should be bounded if we cannot guarantee that the producers will never
be cancelled, and as such are assured to be scheduled again to complete their writes.</p>
<p>Otherwise, a limited number of peek should be attempted, before a warning being issued to avoid
completely blocking the reader. At this point however, any number of messages could be lost in the
queue. If that is a possibility, system recovery would require those elements be made otherwise
reachable by an out-of-band iterator, and a recovery routine implemented stopping the world etc...</p>
<h2>Performance</h2>
<p>The repository linked with this post contains a small benchmark comparing
Vyukov queue to other MPSC queues. This post being too long already, I will
leave actual benchmark for another time, but it is clear that the queue simplicity
makes it interesting, especially as the number of core grows.</p>
</main>

</body>
</html>
