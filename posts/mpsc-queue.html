<!doctype html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="data:,"/>
    <title>U256 | A fast lock-less MPSC queue</title>
    <link rel="stylesheet" href="../style.css"/>

    
</head>
<body>
    <header>
        <div>
            <a href="../">Home</a>
        </div>
<div id='navbar'>
<span><a href="../notes">notes</a></span>
<span><a href="./">posts</a></span>
</div>
    </header>

<main>
    <div class="title">
        <h1>A fast lock-less MPSC queue</h1>
        <time datetime="2021-02-21">2021-02-21</time>
    </div>
<blockquote>
<p>Code available on <a href="https://github.com/grivet/mpsc-queue">github</a>.</p>
</blockquote>
<p>Sharing mutable data kills concurrency.</p>
<p>Following this simple precept, it is possible to tame the complexity of
maintaining concurrency in a system by deriving some rules:</p>
<ul>
<li>Mutable data that is not shared is <em>isolated</em>.</li>
<li>The simplest way to isolate data is to only allow a single reference to it.</li>
<li>If isolated data still needs to be used by multiple actors, it must be safe
to update ownership of the unique reference.</li>
</ul>
<p>The building block to signal ownership changes would be a critical primitive in the system.
For cooperative threads, a message queue can be used, which is easy to implement.</p>
<p>I found the <a href="http://www.1024cores.net/home/lock-free-algorithms/queues/intrusive-mpsc-node-based-queue">queue described by Dmitri Vyukov</a> simple and practical.
It offers interesting properties but has important caveats that should be highlighted.</p>
<h2>Taxonomy</h2>
<p>This message queue is <strong>intrusive</strong> which is great for performance systems. It follows
that the queue is <strong>unbounded</strong>, as any item could hold a new node to enqueue.</p>
<p>Ordering is <strong>per-producer FIFO</strong>, i.e. it keeps the order of insertions from each producer point of view.
However, between producers no ordering is guaranteed, unless additional synchronization is used.</p>
<p>Insertion is done in a finite and constant number of steps by any number of producers.
State synchronization is done at a single point using an atomic exchange. This is lighter than
compare-exchange based queues as there is no loop to resolve concurrent writes.</p>
<p>Reading the queue state and removing elements is only allowed to a single consumer at a time.
Peeking at the tail of the queue is done in a finite and constant number of steps, like insertion.
Removal however requires producers to complete their writes (more on why below), making the consumer
dependent on other threads forward-progress.</p>
<p>As insertion and removal are both <strong>exchange</strong> based, instead of <strong>compare-exchange</strong> based, they are
immune from the <em>ABA</em> problem. There is no need to prevent it, further simplifying operations.</p>
<p>Insertion and peeking are finite and constant, but removal, while resolved in constant time as well (either
for success or failure) is dependent on other threads progressing. This makes the queue <strong>obstruction-free</strong>
only, the weakest forward-progress guarantee.</p>
<p>Such structure relies on cooperative peers to avoid livelock. This might not be an issue for some
concurrent systems, but it is important to keep in mind.</p>
<p>This queue can be useful for low-latency systems, such as <em>thread-per-core</em> applications.
It could be used to implement the <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a> as well.</p>
<h2>Operations</h2>
<h3>Insertion</h3>
<p>The queue is implemented using a singly-linked list. Insertion is done at the
back of the queue. First the current end is swapped with the new node atomically.
The previous end is then updated to point to the new node. To follow Vyukov's
nomenclature, the end-node of the chain is the head. A producer will
only manipulate the head.</p>
<p>The head swap is atomic, however the link from the previous head to the new
one is done in a separate operation. This means that the chain is momentarily
broken when the previous head still points to <code>NULL</code> and the current head has
been inserted.</p>
<p>Considering a series of insertions, the queue state will remain consistent
and their order is compatible with their precedence, thus this operation
is serializable. However, because an insertion consists in two separate memory
transactions, it is not linearizable.</p>
<h3>Removal</h3>
<p>The consumer must deal with the queue inconsistency. It will manipulate
the tail of the queue and move it along the latest consumed elements.
When an end of the chain of elements is found (the next pointer is <code>NULL</code>),
the tail is compared with the head.</p>
<p>If both points to different addresses, then the queue is in an inconsistent
state: the tail cannot move forward as the next is <code>NULL</code>, but the head is not
the last element in the chain: this can only happen if the chain is broken.</p>
<p>In this case, the consumer must wait for the producer to finish writing the
next pointer of its current tail.</p>
<p>Removal is thus in most cases (when there are elements in the queue)
accomplished without using atomics, until the last element of the queue.
There, the head is atomically loaded. If the queue is in a consistent state,
the head is moved back to the queue stub by inserting the stub in the queue:
ending the queue is the same as an insertion, which is one atomic exchange.</p>
<h3>Safety</h3>
<p>Because the queue can be in transient inconsistent states, the reader needs
to peek before removing an element. Finding a consistent state is dependent on
producers completing their writes.</p>
<p>If a producer was suspended after exchanging the head, but before linking to the new one,
the consumer is blocked from reading until the producer resumes. If the producer is cancelled,
then the consumer will never be able to access the remaining entries.</p>
<p>If the producers are very rarely or never suspended, then inconsistent states should
be short and rare. Producers should never insert while being cancellable.</p>
<h2>Usage</h2>
<p>The queue is lockless. To benefit from this property, ideally neither producers nor
consumer should have to take a lock to use it. Unfortunately, this means that there is
no proper way to signal when new elements are available in the queue: the consumer
thread is forced to poll it for new items.</p>
<p>Such polling can be implemented using <strong>exponential backoff</strong> if no other work is expected.
It should reduce useless activity of the consumer thread, at the price of some latency
for the first new element if activity picks up.</p>
<p>This is the reason I named the removal function <code>mpsc_queue_poll</code>. It does not guarantee
to return an element, but will signal when it does.</p>
<p>Also, to properly implement exponential backoff, the consumer thread must differentiate between
seeing the queue empty or in an inconsistent state. Instead of a binary <code>NULL</code>/<code>addr</code> returned for
an item, I defined three polling results:</p>
<ul>
<li><code>MPSC_QUEUE_EMPTY</code>, which means that the queue has no elements and backoff could start.</li>
<li><code>MPSC_QUEUE_ITEM</code>, in which case the given pointer is set to the removed element.</li>
<li><code>MPSC_QUEUE_RETRY</code>, signaling that a producer has not yet finished writing and polling should
be attempted again soon. No need to start backoff.</li>
</ul>
<h2>Performance</h2>
<p>The repository linked with this post contains a small benchmark comparing
Vyukov queue to other MPSC queues. This post being too long already, I will
leave actual benchmark for another time, but it is clear that the queue simplicity
makes it interesting, especially as the number of core grows.</p>
</main>

</body>
</html>
